{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":663459,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":501979,"modelId":517142}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ankh --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:21:58.068222Z","iopub.execute_input":"2025-12-19T16:21:58.068458Z","iopub.status.idle":"2025-12-19T16:22:06.211181Z","shell.execute_reply.started":"2025-12-19T16:21:58.068439Z","shell.execute_reply":"2025-12-19T16:22:06.210454Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ns3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2024.6.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport ankh\nfrom tqdm.auto import tqdm\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom torch.nn.utils.rnn import pad_sequence\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport csv\nimport math\nimport pandas as pd\nfrom transformers.models import convbert\nfrom typing import Optional\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nfrom torch.nn.utils import weight_norm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:22:06.212908Z","iopub.execute_input":"2025-12-19T16:22:06.213134Z","iopub.status.idle":"2025-12-19T16:22:36.727870Z","shell.execute_reply.started":"2025-12-19T16:22:06.213111Z","shell.execute_reply":"2025-12-19T16:22:36.726953Z"}},"outputs":[{"name":"stderr","text":"2025-12-19 16:22:18.981303: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766161339.161287      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766161339.212084      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint('Available device:', device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:22:36.728870Z","iopub.execute_input":"2025-12-19T16:22:36.730014Z","iopub.status.idle":"2025-12-19T16:22:36.734086Z","shell.execute_reply.started":"2025-12-19T16:22:36.729990Z","shell.execute_reply":"2025-12-19T16:22:36.733369Z"}},"outputs":[{"name":"stdout","text":"Available device: cuda:0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"TCN_LEVEL = 3\nNUM_CHANNELS = [256] * TCN_LEVEL\nKERNEL_SIZE = 5\nNUM_HEADS = 8\nDROPOUT = 0.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:22:36.734724Z","iopub.execute_input":"2025-12-19T16:22:36.734923Z","iopub.status.idle":"2025-12-19T16:22:36.848386Z","shell.execute_reply.started":"2025-12-19T16:22:36.734906Z","shell.execute_reply":"2025-12-19T16:22:36.847572Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, input_dim, num_heads, num_layers=1):\n        super().__init__()\n        encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=num_heads)\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n\n    def forward(self, x, padding_mask=None):\n        x = x.transpose(0, 1)\n        x = self.transformer_encoder(x, src_key_padding_mask=padding_mask)\n        x = x.transpose(0, 1)\n        return x\n\nclass Chomp1d(nn.Module):\n    def __init__(self, chomp_size):\n        super(Chomp1d, self).__init__()\n        self.chomp_size = chomp_size\n\n    def forward(self, x):\n        return x[:, :, :-self.chomp_size].contiguous()\n\nclass TemporalBlock(nn.Module):\n    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, dropout):\n        super().__init__()\n        \n        padding = (kernel_size - 1) * dilation\n\n        self.conv1 = nn.Sequential(\n            weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size=kernel_size, padding=padding,\n                                 stride=stride, dilation=dilation)),\n            Chomp1d(padding),\n            nn.ReLU(),\n            nn.Dropout(dropout)\n        )\n        \n        self.conv2 = nn.Sequential(\n            weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size=kernel_size, padding=padding,\n                                 stride=stride, dilation=dilation)),\n            Chomp1d(padding),\n            nn.ReLU(),\n            nn.Dropout(dropout)\n        )\n        \n        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.conv2(out)\n        res = x if self.downsample is None else self.downsample(x)\n        return self.relu(res + out)\n\n\nclass TemporalConvNet(nn.Module):\n    def __init__(self, num_inputs, num_channels, kernel_size, dropout):\n        super().__init__()\n        layers = []\n        num_levels = len(num_channels)\n        for i in range(num_levels):\n            dilation_size = 2 ** i\n            in_channels = num_inputs if i == 0 else num_channels[i-1]\n            out_channels = num_channels[i]\n            layers.append(\n                TemporalBlock(in_channels, out_channels, kernel_size, stride=1,\n                              dilation=dilation_size, dropout=dropout)\n            )\n        self.network = nn.Sequential(*layers)\n        \n\n    def forward(self, x):\n        x = self.network(x)\n        return x\n\nclass BiTCN(nn.Module):\n    def __init__(self, input_dim, num_channels, kernel_size, dropout):\n        super().__init__()\n        self.forward_tcn = TemporalConvNet(input_dim, num_channels, kernel_size, dropout)\n        self.backward_tcn = TemporalConvNet(input_dim, num_channels, kernel_size, dropout)\n\n    def forward(self, x):\n        forward_out = self.forward_tcn(x)\n        backward_out = self.backward_tcn(torch.flip(x, dims=[2]))\n        backward_out = torch.flip(backward_out, dims=[2])\n        out = torch.cat([forward_out, backward_out], dim=1)\n        return out\n\nclass PSSPModel(nn.Module):\n    def __init__(self, num_channels, kernel_size, num_heads, dropout, input_dim=1536, num_layers=1, num_classes=8):\n        super().__init__()\n        self.bitcn = BiTCN(input_dim, num_channels, kernel_size, dropout)\n        self.transformer = Transformer(num_channels[-1]*2, num_heads, num_layers)\n        self.fc = nn.Linear(num_channels[-1]*2, num_classes)\n\n    def forward(self, x, padding_mask=None):\n        x = x.transpose(1, 2)\n        x = self.bitcn(x)\n        x = x.transpose(1, 2)\n        x = self.transformer(x, padding_mask)\n        logits = self.fc(x)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:22:36.849262Z","iopub.execute_input":"2025-12-19T16:22:36.850037Z","iopub.status.idle":"2025-12-19T16:22:36.866030Z","shell.execute_reply.started":"2025-12-19T16:22:36.850015Z","shell.execute_reply":"2025-12-19T16:22:36.865276Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def embed_dataset(model, sequences, shift_left = 0, shift_right = -1):\n    inputs_embedding = []\n    with torch.no_grad():\n        for sample in tqdm(sequences, disable=True):\n            ids = tokenizer.batch_encode_plus([sample], add_special_tokens=True, \n                                              padding=True, is_split_into_words=True, \n                                              return_tensors=\"pt\")\n            embedding = model(input_ids=ids['input_ids'].to(device))[0]\n            embedding = embedding[0].detach().cpu().numpy()[shift_left:shift_right]\n            inputs_embedding.append(embedding)\n    return inputs_embedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:22:36.866835Z","iopub.execute_input":"2025-12-19T16:22:36.867082Z","iopub.status.idle":"2025-12-19T16:22:36.878113Z","shell.execute_reply.started":"2025-12-19T16:22:36.867055Z","shell.execute_reply":"2025-12-19T16:22:36.877470Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def preprocess_data(sequences, max_length=None):\n    \n    sequences = [\"\".join(seq.split()) for seq in sequences]\n    \n    if max_length is None:\n        max_length = len(max(sequences, key=lambda x: len(x)))\n\n    seqs = [list(seq)[:max_length] for seq in sequences]\n\n    return seqs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:22:36.879917Z","iopub.execute_input":"2025-12-19T16:22:36.880294Z","iopub.status.idle":"2025-12-19T16:22:36.890112Z","shell.execute_reply.started":"2025-12-19T16:22:36.880271Z","shell.execute_reply":"2025-12-19T16:22:36.889536Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def prepare_ankh(device):\n    model, tokenizer = ankh.load_large_model()\n    model.eval()\n    model.to(device=device)\n\n    return model, tokenizer\n\n\ndef prepare_pssp(num_channels, kernel_size, num_heads, dropout, device, \n                 path=\"/kaggle/input/bitcn-transformer/pytorch/default/3/5_256_3_8.pt\"):\n    model_pssp = PSSPModel(num_channels=num_channels, \n                  kernel_size=kernel_size,\n                  num_heads=num_heads,\n                 dropout=dropout).to(device)\n    model_pssp.load_state_dict(torch.load(path)['model_state_dict'])\n\n    return model_pssp.eval()\n    \ndef prepare_data(model, sequences, shift_left = 0, shift_right = -1, max_length = None):\n    prepared_seq = preprocess_data(sequences, max_length)\n    embed_seq = embed_dataset(model, prepared_seq, shift_left, shift_right)\n\n    return embed_seq\n\n    \ndef predict_pssp(model_pssp, seq, device):\n    unique_tags = {'B', 'C', 'E', 'G', 'H', 'I', 'S', 'T'}\n    tag2id = {'B': 0, 'C': 1, 'I': 2, 'T': 3, 'S': 4, 'E': 5, 'G': 6, 'H': 7}\n    id2tag = {0: 'B', 1: 'C', 2: 'I', 3: 'T', 4: 'S', 5: 'E', 6: 'G', 7: 'H'}\n\n    seq = torch.tensor(seq).to(device)\n    \n    with torch.no_grad():\n        with torch.cuda.amp.autocast():\n            outputs = model_pssp(seq)\n            \n    preds = outputs.argmax(dim=2).cpu().numpy()\n    \n    pred_seq = []\n    for i in range(preds.shape[0]):\n        for j in range(preds.shape[1]):\n            pred_seq.append(id2tag[preds[i][j]])\n\n    seq_string = \"\".join(pred_seq)\n    \n    return seq_string","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:22:36.890748Z","iopub.execute_input":"2025-12-19T16:22:36.890954Z","iopub.status.idle":"2025-12-19T16:22:36.901381Z","shell.execute_reply.started":"2025-12-19T16:22:36.890938Z","shell.execute_reply":"2025-12-19T16:22:36.900634Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model, tokenizer = prepare_ankh(device=device)\nmodel_pssp = prepare_pssp(num_channels=NUM_CHANNELS, kernel_size=KERNEL_SIZE, num_heads=NUM_HEADS, dropout=DROPOUT, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:22:36.901965Z","iopub.execute_input":"2025-12-19T16:22:36.902236Z","iopub.status.idle":"2025-12-19T16:23:08.503812Z","shell.execute_reply.started":"2025-12-19T16:22:36.902212Z","shell.execute_reply":"2025-12-19T16:23:08.502868Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aab1d54bfb04413a0f6051196514d7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb7c02d881174216a43cf7fef7cc0da0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25cd2598ef4940fe9d62f9d99a9a3ecf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/849 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdb82f983f414e39ab2a94a94407c27b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/7.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6c06f2cec72482eabb543e234a1fae6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/7.51G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4fb801c42a84e37895806705d3dc7ee"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"sequence = input(\"Masukkan sequence asam amino: \")\n\nseq = prepare_data(model=model, sequences=[sequence])\npredicted = predict_pssp(model_pssp=model_pssp, seq=seq, device=device)\nprint(\"Sequence prediksi struktur sekunder: \", predicted)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T16:23:08.504743Z","iopub.execute_input":"2025-12-19T16:23:08.505134Z","iopub.status.idle":"2025-12-19T16:26:00.811329Z","shell.execute_reply.started":"2025-12-19T16:23:08.505101Z","shell.execute_reply":"2025-12-19T16:26:00.810454Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Masukkan sequence asam amino:  TTYADFIASGRTGRRNAIHD\n"},{"name":"stdout","text":"Sequence prediksi struktur sekunder:  CCHHHHHHTTCCCCCCCCCC\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}